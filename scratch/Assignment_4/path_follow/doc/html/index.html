<html><head><meta http-equiv="Content-Type" content="text/html;charset=utf-8">
<title>path_follow: Main Page</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
<script type="text/javascript" src="jquery.js"></script>
</head>
<body onload='searchBox.OnSelectItem(0);'>
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search');
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">path_follow Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><div class="manifest" style="padding: 5px; background-color: #eee; border: 1px solid #333; float: right; width: 25%;">
<h3>path_follow</h3>
<p class=description><em>Path Following Option Assignment</em></p>
<p>
<ul>
<li>Homepage: <a href="http://wiki.ros.org/path_follow">http://wiki.ros.org/path_follow</a></li>
</ul>
</p>

</div>
<p><b>41012</b> Assignment 4: Project ROS Path Following</p>
<h1><a class="anchor" id="Specifics"></a>
Specifics</h1>
<p>The project is based on path following where different point will be sent and the robot will follow and analyse the points to check if they are reachable The starting configuration is the current position of the robot while the path provided uses geometry_msgs/PoseArray message for checkpoints (points on a path) in global coordinates.</p>
<h2><a class="anchor" id="Description"></a>
Description</h2>
<p>Write a series of components using the ROS CBSE framework that will process data originating from a range of sensors on a simulated robot. Employ appropriate multi-threading and data structures to enable time synchronisationand subsequently interrogation of data which allow simple actions of a robotic platform. Supply appropriate auto-generated documentation utilising inline source mark-up. Exploit unit testing framework with test cases evaluating code.</p>
<h2><a class="anchor" id="Rationale"></a>
Rationale</h2>
<p>In a Mechatronics System, sensors produce data at varying rates. Decisions need to be made based on correctly associated data in near real-time. Threading and synchronisation are ways to ensure the system performs as intended, with guarantees on the responsiveness of the system to incoming data changes, processing constraints and system behaviour. Functions that exploit the data require unit testing to ensure they behave correctly. Documentation of your own code allows other developers to utilise it as intended and anticipate outcomes, in the same fashion you use a number of APIs (ROS/OpenCV).</p>
<h2><a class="anchor" id="Details"></a>
Details</h2>
<ul>
<li>Student Name: Esteban Andrade</li>
<li>Student ID: 12824583</li>
</ul>
<h1><a class="anchor" id="usage"></a>
Common Usage</h1>
<p>There are will be two nodes associated with the project. One node will be in charge of the selecting the points. The other one will process the points and will allow to steer the robot. There are two options for this. One that will be In spot rotation and Pure Pursuit. By default Pure pursuit will be off. The unit test is included In order to follow the program run the following Commands</p>
<ul>
<li>To start the Simulation run <pre class="fragment">roslaunch a4_setup a4_setup.launch </pre></li>
<li>To select the Points <pre class="fragment">rosrun path_follow path_follow-select_path </pre> <dl class="section note"><dt>Note</dt><dd>Use Left click to select the poses. Use right click to send the poses</dd></dl>
</li>
<li>To Visualise the Status of the points : completed points (blue), current point being completed(green) and remaining points (red) <pre class="fragment"> RQT and check /map_image/path_following</pre></li>
<li>To Start the analysis of the points and Navigation (Spot Turn) <pre class="fragment">rosrun path_follow path_follow-plot_path </pre></li>
<li>To Start the analysis of the points and Navigation (Pure Pursuit) <pre class="fragment">rosrun path_follow path_follow-plot_path _purePursuit:=true</pre></li>
<li>To Start Unit Test <pre class="fragment">rosrun path_follow path_follow-test </pre></li>
</ul>
<h1><a class="anchor" id="Analysis"></a>
Analysis</h1>
<p>There were several algorithms used in the project that were inplemented for the navigation, Points status analysis and Laser readings.</p>
<h2><a class="anchor" id="Navigation"></a>
Navigation</h2>
<p>For the navigation it is neccesary to estimate the angle of the target and orientate the robot towards that angle. If that angle is in the respective threshold it will go straight, else it will adjust. Once it close to the target with in a specific threshold it will move to the next point. For Pure pursuit the afle gamma was estimated and the value of the velocities(Both Angular and Linear) is adjusted using a gain and gamma.</p>
<h2><a class="anchor" id="Laser"></a>
Laser</h2>
<p>For the laser Scanning it was neccesaty to contrain the field of view, in order to ensire it will cover the majority of the robot. Once the laser detect the a close target it will send a signal to notify the obstruction. With this readings we can avoid obstacles and steer the robot to go to a valid position in space.</p>
<h2><a class="anchor" id="Points"></a>
Points</h2>
<p>In order to check the status of the point it was neccesary to make a line iterator and check if they can connect. This was done by detecting the black pixels in the image. Once it detect a black pixel in the trajectory. The path will be invalid Grey will be acceptable as the status is unknown and it can become either true or false as the robot scans the enviroment. IF the point is invalid it will be removed and it will move to the next one</p>
<h2><a class="anchor" id="Tests"></a>
Tests</h2>
<p>The code was tested using GTEST for this two images were used in order to check the connectivity of the points and verify if they pass or fail. Also two rosbags were used in order to check the laser readings to detect obstacles.</p>
<h2><a class="anchor" id="behaviour"></a>
Expected behaviour</h2>
<p>From the code it is expected that when poses are selected with select_path it will send the poses to plot_path and it will display a raw image of the selected target poses. On this node and refering to rqt , on another thread it will check whether the target point is free or occupied or unknown. If the status is occupied it will pop that element and move to the next one. The colours of the poins will be based on the status either green for the current target point, blue for the completed points and red for the remaining one. Additinally there will be two ways of navigation. On each one make the robot move to the point. Once the robot is in a certain tolorance close to the point it will pop that element and move to the next one. If it detects an obstacle in that path it will pop that element and move to the next one after adjusting the robot position. Furthermore, there will be two possible ways for navigation either on the spot turns or pure Pursuit. Based on this the robot will have a different navigation behaviour as it will depend on the angle gamma for pure pursuit.</p>
<dl class="section note"><dt>Note</dt><dd>The nodes are subscribed to robot_0; These can be remmaped using rosrun for the corresponding nodes. Please check Documentation for remmaping the topics </dd></dl>
</div></div><!-- contents -->

<br clear="all" />
<hr size="1"><div style="align: right;">
<a href="http://wiki.ros.org/path_follow">path_follow</a><br />
Author(s): Esteban Andrade <esgaanza98@gmail.com></br />
<small>autogenerated on Wed Jun 24 2020 17:41:42</small>
</div>
</body>
</html>
